---
title: "Final Paper"
author: "STOR 320.(01 OR 02) Group PLACE_GROUP_NUMBER_HERE (Ex: STOR 320.01 Group 12)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(27) #DO NOT CHANGE THIS SEED IT IS NEEDED FOR REPRODUCABILITY SO OUR DATA WILL MAKE SENSE WITH THE WORDS WE USE PLEASE DONT CHANGE KEEP AT 27 PLEASE GOD KEEP AT 27
library(tidyverse)
library(patchwork)
library(rje)
library(caret)
library(kableExtra)
library(Boruta)
library(plotly)
library(randomForest)
```

```{r, echo= FALSE}
annotations = list( 
  list( 
    x = 0.015,  
    y = 1.0,  
    text = "Adc",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ),  
  list( 
    x = 0.3925,  
    y = 1,  
    text = "Jungle",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ),  
  list( 
    x = 0.715,  
    y = 1,  
    text = "Mid",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ),
  list( 
    x = 0.0375,  
    y = 0.46,  
    text = "Support",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ), 
  list( 
    x = 0.38,  
    y = 0.46,  
    text = "Top",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE 
  ))
```

# INTRODUCTION


```{r}

leaguedf <- read_csv('../data_sets/S13LeagueOfLegendsData.csv', 
                      col_types=c('c', 'c', 'c', 'c', 'c', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'c'), 
                      col_names=c('rowno', 'Name', 'Class', 'Role', 'Tier', 'Score', 'Trend', "WinRate", "RoleRate", "PickRate", "BanRate", 'KDA', 'Patch'), skip=1) %>%
  column_to_rownames("rowno") %>% 
  mutate(PickBanRate = PickRate + BanRate, 
         Patch = as.numeric(str_replace(Patch, '(.*?)_(.*?)', '')), 
         Role = str_to_title(Role))
leaguedf$Tier = as.factor(leaguedf$Tier) %>%
  fct_relevel(c("God", "S", "A", "B", "C", "D"))

head(leaguedf, 5)

```
AFTER WORKING WITH THE DATA AND DISCUSSING THE INFORMATION WITH YOUR GROUP, YOU SHOULD DESCRIBE 2 QUESTIONS THAT ARE CREATIVE AND INNOVATIVE. YOU SHOULD EXPLAIN WHY THESE QUESTIONS ARE INTERESTING AND WHY THEY DESERVE FURTHER INVESTIGATION. I ADVISE TO THINK OF REASONS WHY AN OWNER OF THE DATA MIGHT BENEFIT FROM ANSWERS TO THESE QUESTIONS. THINK OF REASONS WHY THE WORLD MAY BE INTERESTED IN THESE QUESITONS. THE PURPOSE OF THE INTRODUCTION IS TO STATE SOME INTERESTING QUESTIONS AND DEFEND THE VALUE OF THESE QUESTIONS. THIS INTRODUCTION SHOULD BE WRITTEN IN A WAY THAT SHOULD GET THE READER EXCITED ABOUT SEEING YOUR RESULTS. THIS SHOULD BE WRITTEN IN NO MORE THAN 4 PARAGRAPHS.

# DATA

```{r, message = F}
tempchamps <- leaguedf %>%
  complete(nesting(Name, Role), Patch) %>% # This explicitly finds champions who were only played in a role significantly for less than all of the patches!
  filter(!complete.cases(.)) %>%
  count(Name, Role)

tempdf <- leaguedf %>%
  filter(Name %in% tempchamps$Name & complete.cases(.)) %>%
  group_by(Name, Role) %>%
  summarize(
    n = n(),
    meanWinRate = mean(WinRate),
    sdWinRate = sd(WinRate),
    meanPickBan = mean(PickBanRate),
    sdPickBan = sd(PickBanRate), 
    label = paste(Name, '\n', Role, sep = " ")
  ) %>%
  filter(n != 23)

tempdf %>%
  mutate(meanWinRate = meanWinRate * 100, meanPickBan = meanPickBan * 100) %>%
  ggplot(aes(x = meanWinRate, y = meanPickBan)) + geom_point(mapping = aes(size = 1/n)) +
  geom_text(aes(label = label, color = Role), size = 3, nudge_x = 0.5, check_overlap = T) + #Consider removing? Is it too much stuff?
  geom_vline(xintercept = 50, color = 'red') + 
  coord_trans(x = 'log10', y = 'log10') + 
  labs(x = "Win Rate Average", y = "Pick Ban Rate Average", title = "Win Rate vs Pick Ban Rate for Temporary champions", subtitle = "Size is invertly proportional to number of patches present") + 
  theme_minimal()
```

```{r, message = F, warning = F}
leaguedf %>%
  select("Name", "PickBanRate", "WinRate", "Role", "RoleRate", "Class", "Patch") %>%
  filter(!(Class == "NULL")) %>%
  group_by(Role) %>%
  group_map( ~ plot_ly(data = .,
      x = ~ PickBanRate,
      y = ~ WinRate,
      color = ~ Class,
      text = ~ Name,
      frame = ~ Patch, 
      hoverinfo = "text",
      type = "scatter",
      mode = "markers", 
      marker = list(size = ~ RoleRate*5)
      ), .keep = TRUE) %>%
  subplot(nrows = 2, shareX = TRUE, shareY=TRUE, margin=0.03) %>%
  layout(showlegend = FALSE, title = 'Pick Ban Rate vs. Win Rate by Patch seperated by Role',
         plot_bgcolor='#e5ecf6', 
         xaxis = list( 
           zerolinecolor = '#ffff', 
           zerolinewidth = 2, 
           gridcolor = 'ffff'), 
         yaxis = list( 
           zerolinecolor = '#ffff', 
           zerolinewidth = 2, 
           gridcolor = 'ffff'),
         margin = 0.07) %>%
  layout(annotations = annotations)

```



```{r, echo = F}


MakeCorrelationDf <- function(varname, outputname = varname) {
  head(leaguedf)
  tempdf <- leaguedf %>%
    pivot_wider(id_cols = c("Name", "Role"), names_from = "Patch", values_from = varname) %>%
    mutate(ID = paste(Name, Role, sep = ' ')) %>%
    select(-c(1, 2)) %>%
    na.omit()
  NameList <- tempdf$ID
  
  tempdf <- tempdf %>%
    t() %>%
    as_tibble() %>%
    filter(row_number() < n()) %>%
    mutate_if(is.character, as.numeric)

  
  colnames(tempdf) <- NameList
  tempdf <- as_tibble(cor(tempdf))
  rownames(tempdf) <- colnames(tempdf)
  tempdf <- tempdf %>%
    rownames_to_column(var = "Champion1") %>%
    gather(key = "Champion2", value = !!paste(outputname, "Correlation", sep = ''), -Champion1) %>%
    filter(!(.by = Champion1 == Champion2))
  
  return(tempdf)
}
```

```{r, warning = F}
PbrCorrelation <- MakeCorrelationDf("PickBanRate", "Pbr") %>%
  group_by(Champion2) %>%
  arrange(PbrCorrelation) %>%
  mutate(label = case_when(
    row_number() <= 2 ~ str_to_title(str_replace(Champion1, '\\.', ' ')),
    row_number() > n() - 2 ~ str_to_title(str_replace(Champion1, '\\.', ' ')), # This adds a Space into the name where the . is  and uncapitalizes the second role
    Champion2 == "Tahm Kench.Support" & PbrCorrelation > 0.68 ~ "Senna Support", # This is an outlier so labeling is justified, especially since it helps show the part of the plot
    TRUE ~ as.character(NA)
  )) 

PbrCorrelation %>% filter(Champion2 %in% c("Tahm Kench Support", "Senna Support", "Ashe Adc")) %>% 
  ggplot(mapping = aes(x=Champion2, y = PbrCorrelation)) + 
  geom_boxplot() + 
  ggtitle("PBR Correlation Boxplot")+ 
  scale_x_discrete(labels = c("Ashe Adc", "Senna Support", "Tahm Kench Support")) + 
  labs(x = "", y = "Pick Ban Rate Correlation Coefficient", caption = "Minimum and Maximum corelation coefficients are annotated, as well as Senna Support for Tahm Kench Support in order\n to best visualize how the strength of certain counters, replacements, and synergies effect Pick Ban Rate.")  + 
  geom_text(aes(label = label), na.rm = TRUE, hjust = -0.1, size = 3, check_overlap = T) 
```

```{r}
leaguedf %>% 
  group_by(Name) %>% 
  summarise(Mean_pick=mean(PickRate, na.rm = TRUE), Std_pick=sd(PickRate, na.rm=TRUE), Mean_win=mean(WinRate, na.rm = TRUE), Std_win=sd(WinRate, na.rm=TRUE)) %>% 
  arrange(desc(Mean_pick)) %>% 
  ggplot(aes(Mean_pick, Std_win)) + geom_point() + labs(x = "Mean Pick Rate", y = "Standard Deviation Win Rate") + 
  coord_trans(x = 'log10', y = 'log10') + 
  geom_smooth(aes(x = Mean_pick, y = Std_win), method = 'lm', se = F) # THIS LOOKS NON LINEAR BUT IT IS LINEAR, ITS JUST ON A LOG SCALE!!!!

```

```{r, fig.height = 15}
plot1 <- leaguedf %>%
  filter(Name %in% c("Fiora", "Darius", "Garen", "Aatrox", "Jax"), Role == "Top") %>%
  ggplot() + geom_count(aes(x = as.factor(Patch), y = Name, size = PickRate, color = Name)) + labs(x = "Patch", y = "Name", title = "Pick Rate")

plot2 <- leaguedf %>%
  filter(Name %in% c("Fiora", "Darius", "Garen", "Aatrox", "Jax"), Role == "Top") %>%
  ggplot() + geom_count(aes(x = as.factor(Patch), y = Name, size = BanRate, color = Name)) + labs(x = "Patch", y = "Name", title = "Ban Rate")

plot3 <- leaguedf %>%
  filter(Name %in% c("Fiora", "Darius", "Garen", "Aatrox", "Jax"), Role == "Top") %>%
  ggplot() + geom_count(aes(x = as.factor(Patch), y = Name, size = WinRate, color = Name)) + labs(x = "Patch", y = "Name", title = "Win Rate")

(plot1 / plot2/ plot3) + plot_annotation(title = "Analysis of Staple Top Champions")

```
IN LESS THAN 6 PARAGRAPHS, YOU SHOULD DESCRIBE THE DATA USED TO ANSWER THE QUESTIONS. YOU SHOULD EXPLAIN WHERE THE DATA ORIGINATED. FOR EXAMPLE, IT IS GOOD TO KNOW WHO COLLECTED THE DATA. JUST BECAUSE THE DATA CAME FROM KAGGLE, DOESN'T MEAN KAGGLE.COM COLLECTED THE DATA. GIVE AN IN-DEPTH DESCRIPTION OF THE SPECIFIC VARIABLES IN THE DATA REQUIRED TO ANSWER YOUR QUESTIONS. YOU SHOULDN'T DISCUSS ALL VARIABLES IN THE DATA IF YOU DIDN'T USE ALL VARIABLES IN THE DATA. YOU SHOULD EXPLAIN WHAT EACH OBSERVATION REPRESENTS (I.E. PEOPLE, SCHOOLS, STATES, CITIES, PATIENTS FROM A SPECIFIC HOSPITAL). WHAT IS THIS A SAMPLE OF? HOW MANY OBSERVATIONS DO YOU HAVE? AFTER READING THIS SECTION, THE READER SHOULD CLEARLY UNDERSTAND THE SOURCE AND CONTENT OF THE DATA YOU PLAN ON UTILIZING TO ANSWER YOUR QUESTIONS THAT YOU PROPOSED IN THE INTRODUCTION. AT LEAST ONE, DESCRIPTIVE TABLE AND AT LEAST ONE FIGURE SHOULD BE USED HERE TO HELP THE READER UNDERSTAND WHAT THE DATA LOOKS LIKE WITHOUT SEEING THE ENTIRE DATASET. IN ALL FIGURES AND TABLES, ONLY THE VARIABLES OF INTEREST SHOULD BE USED.

# RESULTS

```{r, echo = F}
KMeansPalette <- c("#FFB347", "#9D38BD", "#e4ff33", "#2dd7ed", "#7CFC00", "#EF476F")
TierPalette <- c("#A2B5CF", "#E7DD49", "#8FB0C5", "#F7CAC9", "#C2E0CB", "#D7BDE2")


```

```{r, fig.height = 10, fig.width = 10}
#Cluster Analysis with K-Means


#Step 1: Normalize Data:
#First drop icky Vars and then Dummy encode Name, Class, and Role
#This is a high dimensional Data set

Normaldf <- leaguedf %>%
  select(-c(Tier, Score, Trend, PickRate, BanRate)) %>%
    pivot_wider(names_from = Role,
              values_from = Role,
              values_fn = function(x) 1,
              values_fill = 0) %>%
    mutate(Class = paste("Class: ", Class, sep = '')) %>%
    pivot_wider(names_from = Class,
                values_from = Class,
                values_fn = function(x) 1,
                values_fill = 0) %>%
    pivot_wider(names_from = Name,
                values_from = Name,
                values_fn = function(x) 1,
                values_fill =0) %>%
  mutate(
    WinRate = (WinRate - mean(WinRate))/sd(WinRate),
    RoleRate = (RoleRate - mean(RoleRate))/ sd(RoleRate),
    PickBanRate = (PickBanRate - mean(PickBanRate)) / sd(PickBanRate),
    KDA = (KDA - mean(KDA)) / sd(KDA),
    Patch = (Patch -mean(Patch)) / sd(Patch)
  )
  
#Step 2: Clusterize the Data

data <- kmeans(Normaldf, centers = 6, nstart = 25)

leaguedf$Cluster = as.factor(data$cluster)

#Reproducibility for Graphing purposes

ordering <- leaguedf %>%
  group_by(Cluster) %>%
  summarize(RoleRate = mean(RoleRate)) %>%
  arrange(RoleRate) %>%
  mutate(transformation = row_number())

transform <- function (x) {
  temp <- ordering %>%
    filter(Cluster == x)
  return (temp[[1, 3]])
}

leaguedf$Cluster <- sapply(leaguedf$Cluster, transform)

leaguedf <- leaguedf %>%
  mutate(Cluster = as.factor(Cluster))

plot1a <- leaguedf %>%
  ggplot() + 
  geom_point(mapping = aes(x = KDA, y = WinRate, color = Cluster), size = 0.75, alpha = 0.4) + 
  labs(x = "KDA", y = "Win Rate") + 
  theme_minimal()+ 
  theme(legend.position = "none") + 
  scale_color_manual(values = KMeansPalette)

plot1b <- leaguedf %>%
  ggplot() +
  geom_point(mapping = aes(x = PickBanRate, y = WinRate, color = Cluster), size = 0.75, alpha = 0.4) + 
  labs(x= "Pick/Ban Rate", y= "") + 
  theme_minimal()+ 
  scale_color_manual(values = KMeansPalette)+ 
  theme(legend.position = "bottom")+
     guides(color = guide_legend(override.aes = list(size = 3) ) )

plot1c <- leaguedf %>%
  ggplot() + 
  geom_boxplot(mapping = aes(x = Role, y = RoleRate, color = Cluster), lwd = 0.5) +
    labs(x = "Role", y = "Role %") + 
  theme_minimal() + 
  scale_color_manual(values = KMeansPalette)+ 
  theme(legend.position = "none")
design <- "
12
12
12
12
33
33
33
33
44"

KMeans <- wrap_elements(plot1a + plot1b + plot1c + guide_area() + 
  plot_layout(design = design, guides = "collect") &
  plot_annotation(title = "K Means"))


plot1a <- leaguedf %>%
  ggplot() + 
  geom_point(mapping = aes(x = KDA, y = WinRate, color = Tier), size = 0.75, alpha = 0.4) + 
  labs(x = "KDA", y = "Win Rate") + 
  theme_minimal()+ 
  scale_color_manual(values = TierPalette)+ 
  theme(legend.position = "none")

plot1b <- leaguedf %>%
  ggplot() +
  geom_point(mapping = aes(x = PickBanRate, y = WinRate, color = Tier), size = 0.75, alpha = 0.4) + 
  labs(x= "Pick/Ban Rate", y= "") + 
  theme_minimal()+ 
  scale_color_manual(values = TierPalette)+ 
  theme(legend.position = "bottom")+
     guides(color = guide_legend(override.aes = list(size = 3)))

plot1c <- leaguedf %>%
  ggplot() + 
  geom_boxplot(mapping = aes(x = Role, y = RoleRate, color = Tier), lwd= 0.5) + 
  labs(x = "Role", y = "Role %") + 
  scale_color_manual(values = TierPalette)+ 
  theme_minimal() + 
  theme(legend.position = "none")


Meta_Tiers <- wrap_elements(plot1a + plot1b + plot1c + guide_area() + 
  plot_layout(design = design, guides = "collect") &
  plot_annotation(title = "Meta SRC Tier"))


(KMeans | Meta_Tiers) & plot_annotation(title = "Cluster Analysis") & 
  theme(plot.title = element_text(hjust = 0.5, size = 15, face = 'bold')) 
```

```{r, fig.height = 10, fig.width = 10}
#Hierarchical Clustering
HCluster <- hclust(dist(Normaldf))

plot(HCluster, xlab = '', sub = '', cex = .9) #Dendrogram!!!
```

```{r, fig.height = 10, fig.width = 10}

leaguedf$HClust <- as.factor(cutree(HCluster, 5))

plot1a <- leaguedf %>%
  ggplot() + 
  geom_point(mapping = aes(x = KDA, y = WinRate, color = HClust), size = 0.6, alpha = 0.8) + 
  labs(x = "KDA", y = "Win Rate") + 
  theme_minimal()+ 
  theme(legend.position = "none")

plot1b <- leaguedf %>%
  ggplot() +
  geom_point(mapping = aes(x = PickBanRate, y = WinRate, color = HClust), size = 0.6, alpha = 0.8) + 
  labs(x= "Pick/Ban Rate", y= "Win Rate") + 
  theme_minimal()+ 
  theme(legend.position = "right")+
     guides(color = guide_legend(override.aes = list(size = 3) ) )

plot1c <- leaguedf %>%
  ggplot() + 
  geom_boxplot(mapping = aes(x = Role, y = RoleRate, color = HClust), lwd = 0.5) +
    labs(x = "Role", y = "Role %") + 
  theme_minimal() + 
  theme(legend.position = "none")



((plot1a | plot1b) / plot1c )& 
  plot_layout(guides = "collect") &
  plot_annotation(title = "Hierarchical Cluster Analysis")  & theme(plot.title = element_text(hjust = 0.5, size = 15, face = 'bold'))
```

```{r}
leaguedf %>%
  rename(`Hierarchical Cluster` = HClust) %>%
  group_by(`Hierarchical Cluster`) %>%
  summarize(
            `Mean Win Rate` = mean(WinRate),
            `Mean PB Rate` = mean(PickBanRate),
            `Mean Role %` = mean(RoleRate),
            `Mean KDA` = mean(KDA),
            `Median Patch` = median(Patch),
            `Number of Champs` = n_distinct(Name)) %>%
  kbl() %>%
  kable_classic(full_width = F, html_font = "Times New Roman")
```
- Temporary Names for groups:
  - 1: Below Average win rate champs, possibly overpicked
  - 2: Above Average win rate champs, generally underpicked
  - 3: very low win rate champs
  - 4: highly picked champs
  - 5: Yuumi <3

```{r, message = F}
Propdf <- leaguedf %>%
  group_by(Tier, Cluster) %>%
  summarize(count = n()) %>%
  ungroup() %>%
  group_by(Tier) %>%
  mutate(Proportion = count / sum(count)) %>%
  arrange(desc(Proportion))

heatplot <- Propdf %>%
  ggplot() +
  geom_tile(mapping = aes(x = Tier, y = Cluster, fill = Proportion)) & 
  theme_minimal()

heatplot & plot_annotation(title = "Similarity Heatmap", subtitle="This should feel close to a confusion matrix")
```

Part 2: Classification Exploration

This is an attempt for PCA

```{r}
PCAdf <- leaguedf %>%
  mutate(Class = paste("Class", Class, sep='_')) %>%
  pivot_wider(
    names_from = "Name",
    values_from = "Name",
    values_fn = function (x) 1,
    values_fill = 0
  ) %>%
  pivot_wider(
    names_from = "Role",
    values_from = "Role",
    values_fn = function (x) 1,
    values_fill = 0
  ) %>%
  pivot_wider(
    names_from = "Class",
    values_from = "Class",
    values_fn = function (x) 1,
    values_fill = 0
  ) %>%
  select(-c(Score, Trend, Tier, Cluster, HClust))

PCA1 <- prcomp(PCAdf, center = T, scale = F)

```

```{r}

eigen <- PCA1$sdev^2

eigFrame <- data.frame(dim = factor(1:length(eigen)), eig = eigen)

Principles <- PCA1$rotation %>%
  dimnames
```

Here we choose to do Boruta modeling for feature selection over PCA because PCA requires the variables to be in quantiative form. Because we have a large number of categorical variables with many categories and no inherent ordering (like Name and Role), if we dummy encode our data we would result with around 380 variables, and PCA would have 380! models to fit. This is significantly too large, and even using a Hadamard matrix/Plackett Burmann design of experiments to reduce it to around 380, it still would be too many models. Therefore, we choose a Boruta model, which can naturally deal with high dimensional categorical variables in a uch faster way. A boruta model generates a decision tree in a specific manner and sees how inclusion and emphasis of different variables differently affects the accuracy of a random forest model. Because of this, it is very good at feature selection for Random Forest models, of which the Ranger model which we use is a subset of. Beyond that, it measures importance by gathering Z scores of mean decrease accuracy measure (DAM). 

```{r, eval = T}

#Feature Selection

boruta <- Boruta(Tier ~ ., data = select(leaguedf, -c(Score, Trend, Cluster, HClust)))

plot(boruta, las = 2, cex.axis = 0.7)
```

From the Boruta plot, we can see that WinRate is likely most important, and importantly it will be better for our model to train it on PickRate and BanRate as opposed to PickBanRate. While PickBanRate is still an important variable, we choose to not include it as it overrepresents the value of Picks and Bans in a champions tier, where it could potentially be counted twice as opposed to WinRate, which could only be counted once. Additionally, we see that Patch is least important, but is not unimportant in prediction, which is interesting and suggests that there possibly may be differences between Tier Distributions for patches at some level. 

We choose K-Fold over LOOCV for cross validation because 1) K-Fold requires much less computation power and time and this already took 5 hours, and 2) K-Fold can better estimate model accuracy's for machine learning by reducing bias variance, i.e. training on a smaller set will result in less overfitting. K-Fold cross validation functions as: Partition the dataset $S$ into $k$ sets, $S_1, S_2, \ldots, S_k$, loop over $1$ to $k$ with $i$ as the counter, next train each model on the data set $S - S_i$, then test each model on the sample $S_i$ and record the accuracy. When this is finished we compare the mean of each accuracy to best understand the overall standard deviation.

```{r}


for (colname in colnames(leaguedf)) {
  
  if (is.numeric(leaguedf[[colname]])) {
    leaguedf[[colname]] = c(scale(leaguedf[[colname]]))
  }
}

featurecombs <- powerSet(c('WinRate', 'PickRate', 'Role', 'KDA'))# 2^4 = 16 so 16 samples, for 3 models each with 20 runs gives a total of 960 trained models.
featurecombs <- featurecombs[-1]

leaguedf <- leaguedf %>% select(-c(PickBanRate, HClust, Cluster, Score, Trend)) 


```

```{r}
leaguedf$sample <- sample(1:nrow(leaguedf), nrow(leaguedf))

b = nrow(leaguedf)/10

leaguedf <- leaguedf %>%
  mutate(sample = ceiling(sample/b))


crossdf <- data.frame(sample = rep(1:10, each = 15), svm_linear = 0, svm_radial = 0, ranger = 0, WinRate = 0, PickRate = 0, Role = 0, KDA = 0)



fitControl <- trainControl(method='CV', 
                           number = 3, 
                           verboseIter=F)
```

```{r}
#Using a function here makes sure each model stays local and so we end up with a faster training. Consider using this idea elsewhere in the file!!!
trainandtest <- function (method, traindf, testdf, control) {
  if (method == "ranger" & length(colnames(traindf)) < 3) {
    model <- randomForest(
      Tier ~ .,
      data = traindf,
      mtry = 1
    )
  }
  else {
    model <- train(Tier ~ .,
                   data = traindf,
                   method = method,
                   trControl = control)
    testdf$pred <- predict(model, testdf) 
  }
  
  return(mean(testdf$Tier == testdf$pred))
}

featurecount <- 1
# Something is wronge here:
# MTRY For Ranger is auto failing with 1 feature. How do I set mtry low?
for (feature in featurecombs) {
  for (i in 1:10) {
    traindf <- leaguedf %>%
      filter(!(sample == i)) %>%
      select(all_of(feature), Tier)
    testdf <- leaguedf %>%
      filter(sample == i) %>%
      select(all_of(feature), Tier)
    
    #Train models, find the accuracy on the held out sample, and then record the data into the dataframe
    crossdf[((i-1) * 15) + featurecount, 4] <- trainandtest("ranger", traindf, testdf, fitControl)
    crossdf[((i-1) * 15) + featurecount, 2] <- trainandtest("svmLinear", traindf, testdf, fitControl)
    crossdf[((i-1) * 15) + featurecount, 3] <- trainandtest("svmRadial", traindf, testdf, fitControl)
    
    #Record the feature by putting 1 in the columns that have the feature present
    crossdf[((i-1) * 15) + featurecount, 5] <- "WinRate" %in% feature
    crossdf[((i-1) * 15) + featurecount, 6] <- "PickRate" %in% feature
    crossdf[((i-1) * 15) + featurecount, 7] <- "Role" %in% feature
    crossdf[((i-1) * 15) + featurecount, 8] <- "KDA" %in% feature
    }
  featurecount <- featurecount + 1
  } 
```

```{r}
crossdf 
```

```{r, echo  = F, message = F}
crossdf <- read_csv('crossdf.csv')
```

```{r, echo = F}
write_csv(crossdf, "crossdf.csv")
```

```{r}
crossdf %>%
  ggplot(mapping = aes(x = sample)) + 
  geom_line(mapping = aes(y = svm_linear, color = "blue")) + 
  geom_line(mapping = aes(y = svm_radial, color = "red")) + 
  geom_line(mapping = aes(y = ranger, color = "green")) + 
  labs(x = "Sample", y = "Accuracy", title = "Sample Accuracy Plot") + 
  scale_color_manual(values  = c("blue" = "blue", "red" = "red", "green" = "green"), labels = c("SVM Linear", "SVM Radial", "Ranger"), name = "Model")+ 
  theme_minimal()
  
```
Radial is clearly not the moves, so we instead seek to compare svm linear with ranger. If ranger is not siginificantly better than linear svm, then we keep SVM. Neither are particularly human readable, but we can look at the coefficients of an SVM model in a better way than looking at a 5000 length random forest tree. If Ranger is signficantly better, we keep Ranger!!!

```{r}
colstats <- function (todf, colname, df) {
  col <- df[[colname]]
  
  meancol <- mean(col)
  sdcol <- sd(col)
  
  meancolname <- paste(colname, "Mean", sep = '_')
  sdcolname <- paste(colname, "SD", sep = '_')
  
  todf[[meancolname]] <- meancol
  todf[[sdcolname]] <- sdcol
  
  return (todf)
}

pvalFrame <- tibble(rows = c(0)) %>%
  colstats(colname = "svm_linear", crossdf) %>%
  colstats(colname = "svm_radial", crossdf) %>%
  colstats(colname = "ranger", crossdf)

pvalFrame %>%
  transmute(df = 38, 
            `SVM Linear Mean` = svm_linear_Mean,
            `SVM Linear SD` = svm_linear_SD,
            `Ranger Mean` = ranger_Mean,
            `Ranger SD` = ranger_SD, 
            `T Statistic` = (ranger_Mean - svm_linear_Mean) / (sqrt((svm_linear_SD^2/20 + ranger_SD^2/20))),
            `P Value` = pt(`T Statistic`, df = 38, lower.tail = F)) %>%
  kbl() %>%
  kable_classic(html_font = "Times New Roman", full_width = T)

```
This is significant at p=0.05

```{r}
#Data Splitting 


for (colname in colnames(leaguedf)) {
  
  if (is.numeric(leaguedf[[colname]])) {
    leaguedf[[colname]] = c(scale(leaguedf[[colname]]))
  }
}



inTrain <- createDataPartition(y=leaguedf$Tier, p=0.75, list=FALSE) 

leagueTrain <- leaguedf[ inTrain, ]
leagueTest <- leaguedf[ -inTrain, ]

```

```{r, eval = F}
#Model Fitting
#Current best model
grid <- expand.grid(mtry = c(6,9,12), splitrule=c("extratrees", "gini"), min.node.size=c(1,3,6,10))

fitControl <- trainControl(method='CV', 
                           number = 5, 
                           classProbs = TRUE,
                           verboseIter=FALSE)

rf_fit <- train(Tier ~ .,
             data=leagueTrain,
             method="ranger",
             tuneGrid=grid,
             trControl = fitControl, importance="impurity"
)

saveRDS(rf_fit, "RF_Fit.rds")
```

```{r, eval = F, warning = F}

grid <- expand.grid(C = seq(0, 10, length = 20))


fitControl <- trainControl(method='CV', 
                           number = 5, 
                           verboseIter=FALSE)

svmlin_fit <- train(Tier ~ .,
                 data = leagueTrain,
                 method="svmLinear",
                 trControl = fitControl,
                 tuneGrid = grid)

saveRDS(svmlin_fit, "SVMLin_Fit.rds")
```

```{r, eval = F, warning = F}

grid <- expand.grid(C = seq(4, 5, length = 5), sigma = seq(0.20, 0.3, length = 5))


fitControl <- trainControl(method='CV', 
                           number = 3, 
                           verboseIter=F)

svmrad_fit <- train(Tier ~ .,
                 data = leagueTrain,
                 method="svmRadial",
                 trControl = fitControl,
                 tuneGrid = grid)

saveRDS(svmrad_fit, "SVMRad_Fit.rds")
```

```{r, echo = F}
rf_fit <- readRDS("RF_Fit.rds")
#svmlin_fit <- readRDS("SVMLin_fit.rds")
#svmrad_fit <- readRDS("SVMrad_fit.rds")
```

```{r, eval=FALSE}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

Boundarydf = expand.grid(WinRate = seq(0.4, 0.6, length.out=30),
                         PickRate = seq(0.0, 0.5, length.out= 20), 
                         BanRate = seq(0.0, 0.5, length.out = 20), 
                         RoleRate = seq(0.0, 1, length.out=20),
                         KDA = seq(1, 3, length.out = 30),
                         Role = "Top", 
                         ID = c("Camille_Fighter"), 
                         Patch = 13) %>%
  mutate(Name = str_replace(ID, "_.*", ''),
         Class = str_replace(ID, ".*_", ''))
Boundarydf$tier <- predict(rf_fit, Boundarydf)
Boundarydf <- Boundarydf %>%
  group_by(WinRate, KDA) %>%
  summarize(Tier = Mode(tier)) %>%
  ungroup()

write.csv(Boundarydf, "BoundaryFrame.csv")


```


```{r, echo=FALSE, eval = F} 
#CHange Eval after Frame is created
Boundarydf <- read_csv("BoundaryFrame.csv")
```

```{r, fig.width = 10, eval = F}
#Visualization #1 for Ranger Model
acc_plot <- rf_fit$results %>%  
  mutate(mtry = as.character(mtry), min.node.size = as.character(min.node.size)) %>%
  mutate(mtry = factor(mtry, levels=c("6", "9", "12", "15"), ordered=TRUE),
         min.node.size = factor(min.node.size, levels = c("1","3", "6", "10"), ordered=TRUE)) %>%
  ggplot() + geom_tile(mapping = aes(x=mtry, y=min.node.size, fill=Accuracy)) + facet_wrap(splitrule ~.) + ggtitle("Accuracy for each value") + theme(legend.position = "bottom")

rf_pred <- predict(rf_fit, leagueTest)

cm <- confusionMatrix(rf_pred, leagueTest$Tier, dnn = c("Prediction", "Actual"))
plt <- as.data.frame(cm$table) %>%
  group_by(Actual) %>%
  mutate(Percent = Freq / sum(Freq))

plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))
cm_plot <- ggplot(plt, aes(Prediction,Actual, fill=Percent)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="#009194") +
        labs(x = "Actual",y = "Prediction", title = "Confusion Matrix") +
        scale_y_discrete(labels=c('D', 'C', 'B', 'A', 'S', 'God')) +
        scale_x_discrete(labels=c('God', 'S', 'A', 'B', 'C', 'D')) + theme_minimal() + theme(legend.position = "bottom")

boundary_plot <- leaguedf %>%
  filter(Role == 'Top'& Patch == 23 & (Class == "Fighter"| Class == "Tank"))  %>%
  ggplot() + geom_point(mapping = aes(x = KDA, y = WinRate, color = Tier)) + geom_raster(data = Boundarydf, mappign = aes(x = KDA, y = WinRate, fill = Tier))
  
(acc_plot + cm_plot) /boundary_plot
```


```{r}
#Special Analysis just for TempChamps
#TODO: Fix table format so it isn't disgusting
leagueTest %>%
  group_by(Name, Role) %>%
  mutate(n = n()) %>%
  ungroup()  %>%
  mutate(Temp = n < 23, correct = Tier == Pred_svmlin) %>%
  group_by(Temp) %>%
  summarize(Acc = mean(correct), n = n(), sd = sd(correct)) %>%
  kbl() %>%
  kable_classic()

#Assume that the true probablility is correct. Then, we have H0 as Temp >= NonTemp, and H1 as Temp < NonTemp.

table <- tibble(
  NonTemporary = 0.827, Temporary = 0.766, NonTemporaryN = 4876, TemporaryN = 761, sdTemporary = 0.423, sdNonTemporary = 0.378
) %>%
  mutate(diff  = NonTemporary - Temporary, z = diff/ (sqrt(sdTemporary^2 / TemporaryN + sdNonTemporary^2 / NonTemporaryN)), p = pnorm(q = z, df = TemporaryN + NonTemporaryN - 2, lower.tail = F)) %>%
  kbl() %>%
  kable_classic()


table
```

# CONCLUSION
IN LESS THAN 4 PARAGRAPHS, YOU SHOULD RESTATE YOUR QUESTIONS ALONG WITH YOUR CONCLUSIONS. THE PURPOSE OF THIS SECTION IS TO SUMMARIZE YOUR FINDINGS (SHORT), DEFEND THE IMPORTANCE OF YOUR RESULTS IN THE REAL WORLD (LONG), AND PROVIDE A ROADMAP FOR OTHERS TO CONTINUE THIS WORK (LONG). ARE YOUR CONCLUSIONS WHAT YOU EXPECTED OR UNUSUAL? WHY SHOULD SOMEONE CARE ABOUT THESE RESULTS? HOW COULD THESE RESULTS BE USED IN THE REAL WORLD? YOU SHOULD PROVIDE IDEAS ABOUT FUTURE DIRECTIONS ON WHERE YOUR MODELING COULD POSSIBLY BE IMPROVED. ARE THERE ANY METHODS YOU DIDN'T USE THAT MAY WORK BETTER? IS THERE DATA YOU DIDN'T HAVE ACCESS TO THAT MAY BE USEFUL IN THIS DATA ANALYSIS? 



```{r}


```



